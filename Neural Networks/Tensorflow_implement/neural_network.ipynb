{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training NN with TF and Keras\n",
    "from __future__ import absolute_import, division, print_function\n",
    "# TensorFlow and tf.keras\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read files\n",
    "with open('train.csv',mode='r') as f:\n",
    "    myList_train=[]\n",
    "    for line in f:\n",
    "        terms=line.strip().split(',') # 7*N matrix\n",
    "        myList_train.append(terms)\n",
    "with open('test.csv',mode='r') as f:\n",
    "    myList_test = []\n",
    "    for line in f:\n",
    "        terms=line.strip().split(',') # 7*N matrix\n",
    "        myList_test.append(terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data processing\n",
    "def str_2_flo(data):\n",
    "    for row in data:\n",
    "        for j in range(len(data[0])):\n",
    "            row[j] = float(row[j])\n",
    "    return data\n",
    "\n",
    "def add_cons_feature(data):   # add constant feature 1 to as the last feature before label\n",
    "    label = [row[-1] for row in data]\n",
    "    temp = data\n",
    "    for i in range(len(data)):\n",
    "        temp[i][-1] = 1.0\n",
    "    for i in range(len(data)):\n",
    "        temp[i].append(label[i])\n",
    "    return temp\n",
    "\n",
    "# convert label {0,1} to {-1,1}\n",
    "def polar_label(data):\n",
    "    temp = data\n",
    "    for i in range(len(data)):\n",
    "        temp[i][-1] = 2*data[i][-1]-1\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data dimension: (872, 1, 5)\n",
      "test data dimension: (500, 1, 5)\n"
     ]
    }
   ],
   "source": [
    "# data processing \n",
    "               \n",
    "mylist_train = str_2_flo(myList_train)  #convert to float  types data \n",
    "mylist_test = str_2_flo(myList_test) \n",
    "train_data = add_cons_feature(mylist_train)\n",
    "test_data = add_cons_feature(mylist_test)\n",
    "train_len = len(train_data)   # NO. of samples\n",
    "test_len = len(test_data)\n",
    "dim_s = len(train_data[0]) -1   # sample dimension = 5 (including constant feature)\n",
    "train_labels = np.array([row[-1] for row in train_data ])\n",
    "test_labels = np.array([row[-1] for row in test_data ])\n",
    "train_data_unlabeled = [np.array(row[0:dim_s],ndmin =2) for row in train_data]\n",
    "test_data_unlabeled = [np.array(row[0:dim_s],ndmin =2) for row in test_data]\n",
    "\n",
    "train_data_array = np.array(train_data_unlabeled)  # convert to np.array\n",
    "test_data_array = np.array(test_data_unlabeled)\n",
    "print('train data dimension:', train_data_array.shape)\n",
    "print('test data dimension:', test_data_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 100    # hiden layer width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "# he_normal initializer\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(1,5)),\n",
    "    keras.layers.Dense(width, activation=tf.nn.relu, kernel_initializer= 'glorot_normal',\n",
    "                bias_initializer='zeros'),\n",
    "    keras.layers.Dense(width, activation=tf.nn.relu, kernel_initializer= 'glorot_normal',\n",
    "                bias_initializer='zeros'),\n",
    "    keras.layers.Dense(2, activation=tf.nn.softmax)  \n",
    "    # outputs two confidence levels for label = 0 and label =1\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "872/872 [==============================] - 0s 304us/sample - loss: 0.4577 - acc: 0.7798\n",
      "Epoch 2/20\n",
      "872/872 [==============================] - 0s 47us/sample - loss: 0.0915 - acc: 0.9851\n",
      "Epoch 3/20\n",
      "872/872 [==============================] - 0s 43us/sample - loss: 0.0347 - acc: 0.9989\n",
      "Epoch 4/20\n",
      "872/872 [==============================] - 0s 47us/sample - loss: 0.0172 - acc: 1.0000\n",
      "Epoch 5/20\n",
      "872/872 [==============================] - 0s 42us/sample - loss: 0.0099 - acc: 1.0000\n",
      "Epoch 6/20\n",
      "872/872 [==============================] - 0s 47us/sample - loss: 0.0072 - acc: 1.0000\n",
      "Epoch 7/20\n",
      "872/872 [==============================] - 0s 48us/sample - loss: 0.0048 - acc: 1.0000\n",
      "Epoch 8/20\n",
      "872/872 [==============================] - 0s 47us/sample - loss: 0.0037 - acc: 1.0000\n",
      "Epoch 9/20\n",
      "872/872 [==============================] - 0s 42us/sample - loss: 0.0030 - acc: 1.0000\n",
      "Epoch 10/20\n",
      "872/872 [==============================] - 0s 46us/sample - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 11/20\n",
      "872/872 [==============================] - 0s 47us/sample - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 12/20\n",
      "872/872 [==============================] - 0s 48us/sample - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 13/20\n",
      "872/872 [==============================] - 0s 54us/sample - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 14/20\n",
      "872/872 [==============================] - 0s 49us/sample - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 15/20\n",
      "872/872 [==============================] - 0s 47us/sample - loss: 0.0010 - acc: 1.0000\n",
      "Epoch 16/20\n",
      "872/872 [==============================] - 0s 47us/sample - loss: 9.2750e-04 - acc: 1.0000\n",
      "Epoch 17/20\n",
      "872/872 [==============================] - 0s 50us/sample - loss: 8.2041e-04 - acc: 1.0000\n",
      "Epoch 18/20\n",
      "872/872 [==============================] - 0s 53us/sample - loss: 7.3065e-04 - acc: 1.0000\n",
      "Epoch 19/20\n",
      "872/872 [==============================] - 0s 56us/sample - loss: 6.6534e-04 - acc: 1.0000\n",
      "Epoch 20/20\n",
      "872/872 [==============================] - 0s 55us/sample - loss: 6.0601e-04 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x134d5f1f518>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model training/fitting\n",
    "model.fit(train_data_array, train_labels, epochs= 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 0s 162us/sample - loss: 6.0494e-04 - acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# prediction\n",
    "test_loss, test_acc = model.evaluate(test_data_array, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
